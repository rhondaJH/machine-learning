{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Appointment No Shows  with Amazon SageMaker XGBoost\n",
    "_**Supervised Learning with Gradient Boosted Trees: A Binary Prediction Problem**_\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Prepration](#Preparation)\n",
    "1. [Data](#Data)\n",
    "    1. [Exploration](#Exploration)\n",
    "    1. [Transformation](#Transformation)\n",
    "1. [Training](#Training)\n",
    "1. [Hosting](#Hosting)\n",
    "1. [Evaluation](#Evaluation)\n",
    "1. [Exentsions](#Extensions)\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "\n",
    "This notebook uses XGBoost to predict whether a patient will be a no-show for a medical appointment.The dataset was downloaded from Kaggle https://www.kaggle.com/joniarroba/noshowappointments. The appointment data of 110,527 records was collected from medical clinics in the city of Vitoria, Brazil, over a three month period in 2016.\n",
    "\n",
    "The following steps were undertaken:\n",
    "\n",
    "* Preparing your Amazon SageMaker notebook\n",
    "* Downloading data from the internet into Amazon SageMaker\n",
    "* Investigating and transforming the data so that it can be fed to Amazon SageMaker algorithms\n",
    "* Estimating a model using the Gradient Boosting algorithm\n",
    "* Evaluating the effectiveness of the model\n",
    "* Setting the model up to make on-going predictions\n",
    "\n",
    "---\n",
    "\n",
    "## Preparation\n",
    "\n",
    "_This notebook was created and tested on an ml.m4.xlarge notebook instance._\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s).\n",
    "\n",
    "## Notes\n",
    "Tried a simplified model with only a few features to see if that any impact on the recall. It didn't improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "isConfigCell": true,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "bucket = 'sagemaker-sf-strategenics'\n",
    "prefix = 'sagemaker/DEMO-xgboost-noShow'\n",
    " \n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring in the Python libraries that we'll use throughout the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from datetime import time\n",
    "from datetime import datetime\n",
    "import numpy as np                                # For matrix operations and numerical processing\n",
    "import pandas as pd                               # For munging tabular data\n",
    "import matplotlib.pyplot as plt                   # For charts and visualizations\n",
    "from IPython.display import Image                 # For displaying images in the notebook\n",
    "from IPython.display import display               # For displaying outputs in the notebook\n",
    "from time import gmtime, strftime                 # For labeling SageMaker models, endpoints, etc.\n",
    "import sys                                        # For writing outputs to notebook\n",
    "import math                                       # For ceiling function\n",
    "import json                                       # For parsing hosting outputs\n",
    "import os                                         # For manipulating filepath names\n",
    "import sagemaker                                  # Amazon SageMaker's Python SDK provides many helper functions\n",
    "from sagemaker.predictor import csv_serializer    # Converts strings for HTTP POST requests on inference\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data\n",
    "The csv file containing the data is stored in an S3 bucket. First let's read the data file into a Pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110527 entries, 0 to 110526\n",
      "Data columns (total 14 columns):\n",
      "PatientId         110527 non-null float64\n",
      "AppointmentID     110527 non-null int64\n",
      "Gender            110527 non-null object\n",
      "ScheduledDay      110527 non-null object\n",
      "AppointmentDay    110527 non-null object\n",
      "Age               110527 non-null int64\n",
      "Neighbourhood     110527 non-null object\n",
      "Scholarship       110527 non-null int64\n",
      "Hipertension      110527 non-null int64\n",
      "Diabetes          110527 non-null int64\n",
      "Alcoholism        110527 non-null int64\n",
      "Handcap           110527 non-null int64\n",
      "SMS_received      110527 non-null int64\n",
      "No-show           110527 non-null object\n",
      "dtypes: float64(1), int64(8), object(5)\n",
      "memory usage: 11.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data_key = 'appointmentData.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "\n",
    "noShow= pd.read_csv(data_location)\n",
    "\n",
    "pd.set_option('display.max_columns', 500)     # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 20)         # Keep the output on one page\n",
    "noShow\n",
    "noShow.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by renaming some of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PatientId', 'AppointmentID', 'Gender', 'ScheduledDay',\n",
      "       'AppointmentDay', 'Age', 'Neighbourhood', 'Scholarship', 'Hypertension',\n",
      "       'Diabetes', 'Alcoholism', 'Disabilities', 'SMS_received', 'No-show'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "noShow.rename(columns = {'Hipertension': 'Hypertension',\n",
    "                         'Handcap': 'Disabilities'}, inplace = True)\n",
    "\n",
    "print(noShow.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have the date that the appointment was scheduled and the date of the appointment, we can calculate the number of days that the patient waited for the appointment.\n",
    "\n",
    "First we have to convert the two date columns to a date format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2016-04-29\n",
      "1    2016-04-29\n",
      "2    2016-04-29\n",
      "3    2016-04-29\n",
      "4    2016-04-29\n",
      "Name: AppointmentBooked, dtype: object\n",
      "0    2016-04-29\n",
      "1    2016-04-29\n",
      "2    2016-04-29\n",
      "3    2016-04-29\n",
      "4    2016-04-29\n",
      "Name: AppointmentDate, dtype: object\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: WaitingTime, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#convert date columns to a date format\n",
    "noShow['tempSchedDate'] = pd.to_datetime(noShow['ScheduledDay'])\n",
    "noShow['tempAppDate'] = pd.to_datetime(noShow['AppointmentDay'])\n",
    "#get the date part of the date columns, as the Scheduled date has a time component but the appointment day does not\n",
    "noShow['AppointmentDate']= noShow['tempAppDate'].dt.date\n",
    "noShow['AppointmentBooked']= noShow['tempSchedDate'].dt.date\n",
    "#calculate the waiting time\n",
    "noShow['WaitingTime'] = (noShow.AppointmentDate - noShow.AppointmentBooked).dt.days\n",
    "\n",
    "print(noShow.AppointmentBooked.head())\n",
    "print(noShow.AppointmentDate.head())\n",
    "print(noShow.WaitingTime.head())\n",
    "pd.set_option('display.max_columns', 500)     # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 20)         # Keep the output on one page\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the day of the week for the appointment day and drop the original scheduled and appointment columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2016-04-29\n",
      "1    2016-04-29\n",
      "2    2016-04-29\n",
      "3    2016-04-29\n",
      "4    2016-04-29\n",
      "Name: AppointmentDate, dtype: object\n",
      "0    Friday\n",
      "1    Friday\n",
      "2    Friday\n",
      "3    Friday\n",
      "4    Friday\n",
      "Name: DayOfWeek, dtype: object\n",
      "Day of week: ['Friday', 'Monday', 'Saturday', 'Thursday', 'Tuesday', 'Wednesday']\n"
     ]
    }
   ],
   "source": [
    "#Find the day of the week of the appointment\n",
    "noShow['DayOfWeek'] = noShow['tempAppDate'].dt.day_name()\n",
    "\n",
    "#drop the columns no longer needed\n",
    "noShow = noShow.drop(['ScheduledDay','AppointmentDay','tempSchedDate','tempAppDate'], axis=1)\n",
    "\n",
    "print(noShow.AppointmentDate.head())\n",
    "print(noShow.DayOfWeek.head())\n",
    "print('Day of week:', sorted(noShow.DayOfWeek.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that we don't have any duplicate data by looking at the appointmentID which should be unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total appointments: ' + format(noShow.shape[0], \",d\"))\n",
    "print('Unique appointments: ' + format(noShow['AppointmentID'].unique().shape[0], \",d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    There are no duplicate Appointment IDs so we will index the data by AppointmentID. We also need to convert PatientId to an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     29872499824296\n",
      "1    558997776694438\n",
      "2      4262962299951\n",
      "3       867951213174\n",
      "4      8841186448183\n",
      "Name: PatientId, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "noShow.PatientId = noShow.PatientId.astype('int64')\n",
    "print(noShow.PatientId.head())\n",
    "noShow.set_index('AppointmentID', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noShow\n",
    "noShow.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration\n",
    "Let's start exploring the data.  First, let's understand how the features are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Frequency tables for each categorical feature\n",
    "for column in noShow.select_dtypes(include=['object']).columns:\n",
    "    display(pd.crosstab(index=noShow[column], columns='% observations', normalize='columns'))\n",
    "    \n",
    "\n",
    "# Histograms for each numeric features\n",
    "display(noShow.describe())\n",
    "%matplotlib inline\n",
    "hist = noShow.hist(bins=30, figsize=(10, 10))\n",
    "\n",
    "print('Age:', sorted(noShow.Age.unique()))\n",
    "print('Waiting time:', sorted(noShow.WaitingTime.unique()))\n",
    "display(pd.crosstab(index=noShow['DayOfWeek'],columns='DayOfWeek'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data Summary\n",
    "\n",
    "* There are 110,527 patient records, and 13 features for each patient\n",
    "* The features are mixed; some numeric, some categorical\n",
    "\n",
    "\n",
    "*Features:*\n",
    "* `Age`: Patient's age. Integer -1 to 115\n",
    "* `Gender`: Patient's gender, string M,F\n",
    "* `Alcoholism`: Binary, 1=yes\n",
    "* `Diabetes`:Binary, 1= yes\n",
    "* `Hypertension`:Binary, 1= yes\n",
    "* `Disabilities`: The number of disabilities for a patient. Integer, 1-4\n",
    "* `Scholarship`: This indicates whether the patient receives financial support from the government. Binary, 1=yes\n",
    "* `Neighbourhood`: This is the location of the medical clinic. String, 80 values\n",
    "* `SMS_receceived`:Whether they received a SMS reminder before the appointment. Binary, 1= yes\n",
    "* `AppointmentBooked`: Date that the appointment was booked\n",
    "* `AppointmentDate`: Date of the appointment\n",
    "* `DayOfWeek`: The weekday of the appointment. Integer, 0-5\n",
    "* `WaitingTime`: The number of days between booking the appointment and the appointment date. Integer, -6 to 179\n",
    "\n",
    "\n",
    "*Target variable:*\n",
    "* `No-show`: Was the patient a no-show? Binary: 1=yes,0=no\n",
    "Overall, 20% of the patients were no-shows."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now we need to deal with any values that are obviously incorrect. \n",
    "\n",
    "There is an age value of -1 so we will recode that to a missing value. While the oldest age is quite old at 115, it's certainly not impossible to have someone of that age so we will leave that value as it is.\n",
    "\n",
    "There are also some negative values for WaitingTime, so we will also recode these to missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    110522.000000\n",
       "mean         10.184253\n",
       "std          15.255115\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           4.000000\n",
       "75%          15.000000\n",
       "max         179.000000\n",
       "Name: WaitingTime, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noShow['Age'] = np.where(noShow['Age']<0, np.nan, noShow['Age'])\n",
    "noShow['Age'].describe()\n",
    "noShow['WaitingTime'] = np.where(noShow['WaitingTime']<0, np.nan, noShow['WaitingTime'])\n",
    "noShow['WaitingTime'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disability has values from 0-5, indicating the number of disabilities a patient has. We will turn this into a binary column to indicate whether the patient has a disablity or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disability: [0, 1]\n",
      "Disability  Disabilities\n",
      "0           0               108286\n",
      "1           1                 2042\n",
      "            2                  183\n",
      "            3                   13\n",
      "            4                    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "noShow['Disability'] = np.where(noShow['Disabilities']>1, 1, noShow['Disabilities'])\n",
    "print('Disability:', sorted(noShow.Disability.unique()))\n",
    "count = noShow.groupby(['Disability', 'Disabilities']).size() \n",
    "print(count)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now we will look at patient history as it is possible that people who have a previous no-show are more likely to no-show again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PreviousAppointment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt; 5</th>\n",
       "      <td>4264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PreviousAppointment\n",
       "0                  62299\n",
       "1                  24379\n",
       "2                  10484\n",
       "3                   4984\n",
       "4                   2617\n",
       "5                   1498\n",
       "> 5                 4264"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#determine if a patient has had a previous appointment\n",
    "noShow.sort_values(by=['PatientId','AppointmentDate'], inplace=True)\n",
    "pd.options.display.max_rows=100\n",
    "noShow['PreviousAppointment'] = noShow.sort_values(by = ['PatientId','AppointmentDate']).groupby(['PatientId']).cumcount()\n",
    "#print(noShow[['PatientId','AppointmentDate', 'PreviousAppointment']].head(100)) \n",
    "\n",
    "\n",
    "a = noShow.groupby(pd.cut(noShow.PreviousAppointment, bins = [-1, 0,1,2,3,4,5, 85], include_lowest = True))[['PreviousAppointment']].count()\n",
    "b = pd.DataFrame(a)\n",
    "b.set_index(pd.Series(['0', '1', '2', '3', '4', '5', '> 5']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculate whether the patient has a previous no-show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No-show  NoShow\n",
      "No       0         88208\n",
      "Yes      1         22319\n",
      "dtype: int64\n",
      "               PatientId AppointmentDate No-show  PreviousAppointment  PreviousNoShows  PreviousNoShowProp\n",
      "AppointmentID                                                                                             \n",
      "5751990            39217      2016-06-03      No                    0                0                 NaN\n",
      "5760144            43741      2016-06-01      No                    0                0                 NaN\n",
      "5712759            93779      2016-05-18      No                    0                0                 NaN\n",
      "5637648           141724      2016-05-02      No                    0                0                 NaN\n",
      "5637728           537615      2016-05-06      No                    0                0                 NaN\n",
      "5680449          5628261      2016-05-13     Yes                    0                0                 NaN\n",
      "5718578         11831856      2016-05-19      No                    0                0                 NaN\n",
      "5580835         22638656      2016-05-03      No                    0                0                 NaN\n",
      "5715081         22638656      2016-06-08      No                    1                0            0.000000\n",
      "5704816         52168938      2016-05-16      No                    0                0                 NaN\n",
      "5607220         52168938      2016-05-17      No                    1                0            0.000000\n",
      "5613714         54223998      2016-05-11      No                    0                0                 NaN\n",
      "5762797         61433777      2016-06-02      No                    0                0                 NaN\n",
      "5671723         62497926      2016-05-11      No                    0                0                 NaN\n",
      "5683383         64851211      2016-05-13     Yes                    0                0                 NaN\n",
      "5697532         64851211      2016-05-17      No                    1                1            1.000000\n",
      "5640016         78385479      2016-05-02      No                    0                0                 NaN\n",
      "5742958         79228495      2016-05-30      No                    0                0                 NaN\n",
      "5743266         79228495      2016-06-08      No                    1                0            0.000000\n",
      "5672306         86584742      2016-05-13      No                    0                0                 NaN\n",
      "5651939         87996454      2016-05-13     Yes                    0                0                 NaN\n",
      "5786272         87996454      2016-06-08      No                    1                1            1.000000\n",
      "5655338         95313115      2016-05-04      No                    0                0                 NaN\n",
      "5694967         99512431      2016-05-13      No                    0                0                 NaN\n",
      "5556646        122451254      2016-05-02     Yes                    0                0                 NaN\n",
      "5576521        122451254      2016-05-09     Yes                    1                1            1.000000\n",
      "5564358        132818181      2016-05-10      No                    0                0                 NaN\n",
      "5683430        142133299      2016-05-16     Yes                    0                0                 NaN\n",
      "5767863        142133299      2016-06-07      No                    1                1            1.000000\n",
      "5693848        156223164      2016-05-13      No                    0                0                 NaN\n",
      "5729757        156223164      2016-05-24      No                    1                0            0.000000\n",
      "5568452        178168233      2016-05-02      No                    0                0                 NaN\n",
      "5647593        178168233      2016-05-02      No                    1                0            0.000000\n",
      "5713308        179874775      2016-05-24     Yes                    0                0                 NaN\n",
      "5663856        188964456      2016-05-18      No                    0                0                 NaN\n",
      "5724671        188964456      2016-05-20      No                    1                0            0.000000\n",
      "5729804        188964456      2016-05-24      No                    2                0            0.000000\n",
      "5741812        211124677      2016-06-02      No                    0                0                 NaN\n",
      "5761936        211124677      2016-06-08      No                    1                0            0.000000\n",
      "5410598        215778678      2016-05-02     Yes                    0                0                 NaN\n",
      "5760254        223798575      2016-06-01      No                    0                0                 NaN\n",
      "5767077        223798575      2016-06-02      No                    1                0            0.000000\n",
      "5664307        226438321      2016-05-05      No                    0                0                 NaN\n",
      "5631928        243921212      2016-05-03      No                    0                0                 NaN\n",
      "5618607        251541539      2016-05-13     Yes                    0                0                 NaN\n",
      "5692489        251541539      2016-05-19      No                    1                1            1.000000\n",
      "5737747        251541539      2016-05-25      No                    2                1            0.500000\n",
      "5721140        251541539      2016-06-01      No                    3                1            0.333333\n",
      "5563137        253866521      2016-04-29      No                    0                0                 NaN\n",
      "5736655        264963387      2016-05-25      No                    0                0                 NaN\n",
      "5722094        269919126      2016-05-20      No                    0                0                 NaN\n",
      "5722676        269919126      2016-05-20      No                    1                0            0.000000\n",
      "5632535        274297149      2016-05-18      No                    0                0                 NaN\n",
      "5755274        318339487      2016-06-01      No                    0                0                 NaN\n",
      "5559991        318385314      2016-04-29      No                    0                0                 NaN\n",
      "5615460        319947764      2016-05-19      No                    0                0                 NaN\n",
      "5761778        339497234      2016-06-08      No                    0                0                 NaN\n",
      "5651429        342478778      2016-05-17     Yes                    0                0                 NaN\n",
      "5777855        342954879      2016-06-06      No                    0                0                 NaN\n",
      "5785090        342954879      2016-06-08      No                    1                0            0.000000\n",
      "5745118        355744126      2016-06-01      No                    0                0                 NaN\n",
      "5732684        355744126      2016-06-03     Yes                    1                0            0.000000\n",
      "5741517        375356946      2016-05-30      No                    0                0                 NaN\n",
      "5634933        411777183      2016-05-24     Yes                    0                0                 NaN\n",
      "5667149        416673345      2016-05-06      No                    0                0                 NaN\n",
      "5638450        422861257      2016-04-29      No                    0                0                 NaN\n",
      "5640718        422861257      2016-05-02      No                    1                0            0.000000\n",
      "5707143        422861257      2016-05-19      No                    2                0            0.000000\n",
      "5779051        422861257      2016-06-08      No                    3                0            0.000000\n",
      "5695703        427962175      2016-05-13      No                    0                0                 NaN\n",
      "5647345        428834933      2016-05-03      No                    0                0                 NaN\n",
      "5647331        428834933      2016-05-13      No                    1                0            0.000000\n",
      "5739693        481543533      2016-06-02      No                    0                0                 NaN\n",
      "5690546        483277945      2016-05-16     Yes                    0                0                 NaN\n",
      "5753423        483788842      2016-05-31      No                    0                0                 NaN\n",
      "5751174        486736716      2016-06-07     Yes                    0                0                 NaN\n",
      "5661387        499112419      2016-05-05      No                    0                0                 NaN\n",
      "5621161        499252831      2016-05-06     Yes                    0                0                 NaN\n",
      "5633481        499252831      2016-05-13      No                    1                1            1.000000\n",
      "5717472        499252831      2016-05-19      No                    2                1            0.500000\n",
      "5642592        522584745      2016-05-03     Yes                    0                0                 NaN\n",
      "5624326        522584745      2016-05-16     Yes                    1                1            1.000000\n",
      "5624330        522584745      2016-05-16     Yes                    2                2            1.000000\n",
      "5633872        522886422      2016-04-29     Yes                    0                0                 NaN\n",
      "5679224        522886422      2016-05-10      No                    1                1            1.000000\n",
      "5618402        529485485      2016-05-02      No                    0                0                 NaN\n",
      "5729007        529485485      2016-06-02      No                    1                0            0.000000\n",
      "5743075        555199469      2016-05-30      No                    0                0                 NaN\n",
      "5743496        555199469      2016-05-30      No                    1                0            0.000000\n",
      "5625612        557358235      2016-05-03      No                    0                0                 NaN\n",
      "5648719        564947796      2016-05-05      No                    0                0                 NaN\n",
      "5367781        564947796      2016-06-08      No                    1                0            0.000000\n",
      "5745251        571943573      2016-05-31      No                    0                0                 NaN\n",
      "5686994        573397883      2016-05-19     Yes                    0                0                 NaN\n",
      "5721339        575362723      2016-05-19      No                    0                0                 NaN\n",
      "5726363        575362723      2016-05-31      No                    1                0            0.000000\n",
      "5721769        575362723      2016-06-02     Yes                    2                0            0.000000\n",
      "5767198        575362723      2016-06-07      No                    3                1            0.333333\n",
      "5616708        579721997      2016-05-02      No                    0                0                 NaN\n",
      "5715794        589194383      2016-06-06     Yes                    0                0                 NaN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    48228.000000\n",
       "mean         0.198413\n",
       "std          0.343029\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.333333\n",
       "max          1.000000\n",
       "Name: PreviousNoShowProp, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noShow['NoShow']=np.where(noShow['No-show'] == \"Yes\", 1,0)\n",
    "count = noShow.groupby(['No-show', 'NoShow']).size() \n",
    "print(count)\n",
    "\n",
    "#noShow['PreviousNoShow'] = (noShow[noShow['PreviousAppointment'] > 0].sort_values(['PatientId', 'AppointmentDate']).groupby(['PatientId'])['NoShow'].cumsum())\n",
    "noShow['NumberOfPreviousNoShow'] = (noShow.sort_values(['PatientId', 'AppointmentDate']).groupby(['PatientId'])['NoShow'].cumsum())\n",
    "noShow['PreviousNoShows']=noShow['NumberOfPreviousNoShow']-noShow['NoShow']\n",
    "noShow['PreviousNoShowProp'] = noShow['PreviousNoShows']/ noShow[noShow['PreviousAppointment'] > 0]['PreviousAppointment']\n",
    "\n",
    "pd.options.display.max_rows=100\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "print(noShow[['PatientId','AppointmentDate', 'No-show', 'PreviousAppointment','PreviousNoShows','PreviousNoShowProp']].head(100)) \n",
    "\n",
    "noShow['PreviousNoShowProp'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now let's look at how our features relate to the probability of not turning up to the appointment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 110527 entries, 5751990 to 5660958\n",
      "Data columns (total 18 columns):\n",
      "PatientId                 110527 non-null int64\n",
      "Gender                    110527 non-null object\n",
      "Age                       110526 non-null float64\n",
      "Neighbourhood             110527 non-null object\n",
      "Scholarship               110527 non-null int64\n",
      "Hypertension              110527 non-null int64\n",
      "Diabetes                  110527 non-null int64\n",
      "Alcoholism                110527 non-null int64\n",
      "Disabilities              110527 non-null int64\n",
      "SMS_received              110527 non-null int64\n",
      "No-show                   110527 non-null object\n",
      "AppointmentDate           110527 non-null object\n",
      "WaitingTime               110522 non-null float64\n",
      "DayOfWeek                 110527 non-null object\n",
      "Disability                110527 non-null int64\n",
      "PreviousAppointment       110527 non-null int64\n",
      "NumberOfPreviousNoShow    110527 non-null int64\n",
      "PreviousNoShowProp        48228 non-null float64\n",
      "dtypes: float64(3), int64(10), object(5)\n",
      "memory usage: 21.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#drop columns that we no longer need\n",
    "noShow = noShow.drop(['NoShow','AppointmentBooked','PreviousNoShows'], axis=1)\n",
    "noShow.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noShow.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change age and waiting time to categorical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WaitingTimeCat(days):\n",
    "    if days == 0:\n",
    "        return '0 days'\n",
    "    elif  days in range(1,8):\n",
    "        return '1-7 days'\n",
    "    elif  days in range(8,15):\n",
    "        return '8-14 days'\n",
    "    elif days in range(15, 29):\n",
    "        return '15-28 days'\n",
    "    else:\n",
    "        return '> 28 days'\n",
    "    \n",
    "def AgeCat(years):\n",
    "    if years in range(0,5):\n",
    "        return '0-4 years'\n",
    "    elif  years in range(5,15):\n",
    "        return '05-14 years'\n",
    "    elif  years in range(15,25):\n",
    "        return '15-24 years'\n",
    "    elif years in range(25, 35):\n",
    "        return '25-34 years'\n",
    "    elif years in range(35, 45):\n",
    "        return '35-44 years'\n",
    "    elif years in range(45, 55):\n",
    "        return '45-54 years'\n",
    "    elif years in range(55, 65):\n",
    "        return '55-64 years'\n",
    "    else:\n",
    "        return '> 64 years'   \n",
    "noShow['WaitingTimeCat'] = noShow.WaitingTime.apply(WaitingTimeCat)\n",
    "noShow['AgeCat'] = noShow.Age.apply(AgeCat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.crosstab(noShow.Age,noShow.AgeCat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(pd.crosstab(index=noShow['PreviousAppointment'],columns='PreviousAppointment'))\n",
    "\n",
    "filterDf = noShow[(noShow['PatientId'] == 822145925426128)]\n",
    "filterDf2 = filterDf[['PatientId','AppointmentDate','No-show','PreviousAppointment','Age','Diabetes']].copy()\n",
    "filterDf2.info()\n",
    "#filterDf.set_index('AppointmentID', inplace = True)\n",
    "print(filterDf2.head(100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummy variables for no-show so that we can calculate the probability of being a no-show\n",
    "\n",
    "\n",
    "noShow['No-show'] = noShow['No-show'].astype('category')\n",
    "noShow2 = noShow.join(pd.get_dummies(noShow['No-show']))\n",
    "\n",
    "\n",
    "noShow2.rename(columns = {'No': 'Attended',\n",
    "                         'Yes': 'NoShow'}, inplace = True)\n",
    "noShow2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df2 = noShow2.groupby('PreviousNoShowProp').sum()\n",
    "df2['NoShowProp'] = df2['NoShow'] / (df2['Attended'] + df2['NoShow'])\n",
    "df2[['NoShowProp']].plot()\n",
    "\n",
    "df2 = noShow2.groupby('PreviousAppointment').sum()\n",
    "df2['NoShowProp'] = df2['NoShow'] / (df2['Attended'] + df2['NoShow'])\n",
    "df2[['NoShowProp']].plot()\n",
    "\n",
    "\n",
    "def plotNoShow(var):\n",
    " df2 = noShow2.groupby([var])['Attended','NoShow'].sum()\n",
    " df2['NoShowProp'] = df2['NoShow'] / (df2['Attended'] + df2['NoShow'])\n",
    " df2[['NoShowProp']].plot(kind='bar',stacked=True,legend=False)\n",
    " df2\n",
    "\n",
    "    \n",
    "plotNoShow('Gender')    \n",
    "plotNoShow('Disabilities')\n",
    "plotNoShow('Alcoholism')\n",
    "plotNoShow('Diabetes')\n",
    "plotNoShow('Scholarship')\n",
    "plotNoShow('Hypertension')\n",
    "plotNoShow('SMS_received')\n",
    "plotNoShow('DayOfWeek')\n",
    "plotNoShow('AgeCat')\n",
    "plotNoShow('WaitingTimeCat')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now have a look at interactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosstabs(var1,var2):\n",
    "     display(pd.crosstab(var1,var2,normalize='index' ))\n",
    "\n",
    "crosstabs(noShow.AgeCat,noShow.Hypertension)\n",
    "crosstabs(noShow.AgeCat,noShow.Diabetes)\n",
    "crosstabs(noShow.AgeCat,noShow.Alcoholism)\n",
    "crosstabs(noShow.AgeCat,noShow.SMS_received)\n",
    "crosstabs(noShow.AgeCat,noShow.Disability)\n",
    "crosstabs(noShow.AgeCat,noShow.Gender)\n",
    "\n",
    "\n",
    "crosstabs(noShow.Hypertension,noShow.Diabetes)\n",
    "crosstabs(noShow.Hypertension,noShow.Alcoholism)\n",
    "crosstabs(noShow.Hypertension,noShow.SMS_received)\n",
    "crosstabs(noShow.Hypertension,noShow.Disability)\n",
    "crosstabs(noShow.Hypertension,noShow.Gender)\n",
    "\n",
    "\n",
    "\n",
    "crosstabs(noShow.Diabetes,noShow.Alcoholism)\n",
    "crosstabs(noShow.Diabetes,noShow.SMS_received)\n",
    "crosstabs(noShow.Diabetes,noShow.Disability)\n",
    "crosstabs(noShow.Diabetes,noShow.Gender)\n",
    "\n",
    "crosstabs(noShow.Alcoholism,noShow.SMS_received)\n",
    "crosstabs(noShow.Alcoholism,noShow.Disability)\n",
    "crosstabs(noShow.Alcoholism,noShow.Gender)\n",
    "\n",
    "crosstabs(noShow.SMS_received,noShow.Disability)\n",
    "crosstabs(noShow.SMS_received,noShow.Gender)\n",
    "\n",
    "crosstabs(noShow.Disability,noShow.Gender)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotInt(var,var2):\n",
    " df2 = noShow2.groupby([var,var2])['Attended','NoShow'].sum()\n",
    " df2['NoShowProp'] = df2['NoShow'] / (df2['Attended'] + df2['NoShow'])\n",
    " print(df2)\n",
    " #df2[['NoShowProp']].plot(kind='bar',stacked=True,legend=False)\n",
    " df2\n",
    "\n",
    "plotInt('Diabetes','Alcoholism')\n",
    "plotInt('Diabetes','Disability')\n",
    "plotInt('Diabetes','Gender')\n",
    "plotInt('Diabetes','Hypertension')\n",
    "plotInt('Diabetes','Scholarship')\n",
    "plotInt('Diabetes','SMS_received')\n",
    "plotInt('Diabetes','DayOfWeek')\n",
    "plotInt('Diabetes','PatientHistory')\n",
    "\n",
    "\n",
    "plotInt('Alcoholism','Disability')\n",
    "plotInt('Alcoholism','Gender')\n",
    "plotInt('Alcoholism','Hypertension')\n",
    "plotInt('Alcoholism','Scholarship')\n",
    "plotInt('Alcoholism','SMS_received')\n",
    "plotInt('Alcoholism','DayOfWeek')\n",
    "plotInt('Alcoholism','PatientHistory')\n",
    "\n",
    "\n",
    "plotInt('Disability','Gender')\n",
    "plotInt('Disability','Hypertension')\n",
    "plotInt('Disability','Scholarship')\n",
    "plotInt('Disability','SMS_received')\n",
    "plotInt('Disability','DayOfWeek')\n",
    "plotInt('Disability','PatientHistory')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for correlation between age and waiting time\n",
    "plt.scatter(noShow2.Age, noShow2.PreviousNoShowProp, c=noShow2.NoShow)\n",
    "plt.xlabel(\"Age\", fontsize=12)\n",
    "plt.ylabel(\"Previous No-show Prop\", fontsize=12)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some evidence of interaction between the variables, so we will keep all columns in the model. For the first model we will drop neighbourhood as there are more than 80 different values and a lot of sparsity. Would be interesting to add back in later to see how XGBoost handles it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 110527 entries, 5751990 to 5660958\n",
      "Data columns (total 5 columns):\n",
      "No-show               110527 non-null object\n",
      "Gender                110527 non-null object\n",
      "AgeCat                110527 non-null object\n",
      "WaitingTimeCat        110527 non-null object\n",
      "PreviousNoShowProp    48228 non-null float64\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 5.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PreviousNoShowProp</th>\n",
       "      <th>No-show_No</th>\n",
       "      <th>No-show_Yes</th>\n",
       "      <th>Gender_F</th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>AgeCat_0-4 years</th>\n",
       "      <th>AgeCat_05-14 years</th>\n",
       "      <th>AgeCat_15-24 years</th>\n",
       "      <th>AgeCat_25-34 years</th>\n",
       "      <th>AgeCat_35-44 years</th>\n",
       "      <th>AgeCat_45-54 years</th>\n",
       "      <th>AgeCat_55-64 years</th>\n",
       "      <th>AgeCat_&gt; 64 years</th>\n",
       "      <th>WaitingTimeCat_0 days</th>\n",
       "      <th>WaitingTimeCat_1-7 days</th>\n",
       "      <th>WaitingTimeCat_15-28 days</th>\n",
       "      <th>WaitingTimeCat_8-14 days</th>\n",
       "      <th>WaitingTimeCat_&gt; 28 days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AppointmentID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5751990</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5760144</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5712759</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5637648</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5637728</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PreviousNoShowProp  No-show_No  No-show_Yes  Gender_F  Gender_M  AgeCat_0-4 years  AgeCat_05-14 years  AgeCat_15-24 years  AgeCat_25-34 years  AgeCat_35-44 years  AgeCat_45-54 years  AgeCat_55-64 years  AgeCat_> 64 years  WaitingTimeCat_0 days  WaitingTimeCat_1-7 days  WaitingTimeCat_15-28 days  WaitingTimeCat_8-14 days  WaitingTimeCat_> 28 days\n",
       "AppointmentID                                                                                                                                                                                                                                                                                                                                                             \n",
       "5751990                       NaN           1            0         1         0                 0                   0                   0                   0                   1                   0                   0                  0                      0                        1                          0                         0                         0\n",
       "5760144                       NaN           1            0         0         1                 0                   0                   0                   0                   1                   0                   0                  0                      1                        0                          0                         0                         0\n",
       "5712759                       NaN           1            0         1         0                 0                   0                   0                   1                   0                   0                   0                  0                      1                        0                          0                         0                         0\n",
       "5637648                       NaN           1            0         0         1                 0                   1                   0                   0                   0                   0                   0                  0                      0                        1                          0                         0                         0\n",
       "5637728                       NaN           1            0         1         0                 0                   1                   0                   0                   0                   0                   0                  0                      0                        1                          0                         0                         0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop PatientID, AppointmentID and Neightbourhood - check whether we can drop and index column\n",
    "#noShow = noShow.drop(['PatientID','Neighbourhood','AppointmentID'], axis=1)\n",
    "\n",
    "noShowFinal = noShow[['No-show', 'Gender', 'AgeCat','WaitingTimeCat','PreviousNoShowProp']].copy()\n",
    "noShowFinal.info()\n",
    "#create indicator columns for categorical columns, as requried by XGBoost\n",
    "model_data = pd.get_dummies(noShowFinal) \n",
    "model_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No-show\n",
      "No     88208\n",
      "Yes    22319\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count = noShow.groupby(['No-show']).size()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training data (70%), validation data (20%) and prediction data (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = np.split(model_data.sample(frac=1, random_state=8147), [int(0.7 * len(model_data)), int(0.9 * len(model_data))])   # Randomly sort the data then split out first 70%, second 20%, and last 10%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77368, 18)\n",
      "(22106, 18)\n",
      "(11053, 18)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 77368 entries, 5664524 to 5716188\n",
      "Data columns (total 18 columns):\n",
      "PreviousNoShowProp           33807 non-null float64\n",
      "No-show_No                   77368 non-null uint8\n",
      "No-show_Yes                  77368 non-null uint8\n",
      "Gender_F                     77368 non-null uint8\n",
      "Gender_M                     77368 non-null uint8\n",
      "AgeCat_0-4 years             77368 non-null uint8\n",
      "AgeCat_05-14 years           77368 non-null uint8\n",
      "AgeCat_15-24 years           77368 non-null uint8\n",
      "AgeCat_25-34 years           77368 non-null uint8\n",
      "AgeCat_35-44 years           77368 non-null uint8\n",
      "AgeCat_45-54 years           77368 non-null uint8\n",
      "AgeCat_55-64 years           77368 non-null uint8\n",
      "AgeCat_> 64 years            77368 non-null uint8\n",
      "WaitingTimeCat_0 days        77368 non-null uint8\n",
      "WaitingTimeCat_1-7 days      77368 non-null uint8\n",
      "WaitingTimeCat_15-28 days    77368 non-null uint8\n",
      "WaitingTimeCat_8-14 days     77368 non-null uint8\n",
      "WaitingTimeCat_> 28 days     77368 non-null uint8\n",
      "dtypes: float64(1), uint8(17)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(validation_data.shape)\n",
    "print(test_data.shape)\n",
    "train_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No-show_Yes\n",
      "0    8776\n",
      "1    2277\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count = test_data.groupby(['No-show_Yes']).size()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker's XGBoost container expects data in the libSVM or CSV data format.  For this example, we'll stick to CSV.  Note that the first column must be the target variable and the CSV should not include headers.  Also, notice that although repetitive it's easiest to do this after the train|validation|test split rather than before.  This avoids any misalignment issues due to random reordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([train_data['No-show_Yes'], train_data.drop(['No-show_No', 'No-show_Yes'], axis=1)], axis=1).to_csv('train.csv', index=False, header=False)\n",
    "pd.concat([validation_data['No-show_Yes'], validation_data.drop(['No-show_No', 'No-show_Yes'], axis=1)], axis=1).to_csv('validation.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll copy the file to S3 for Amazon SageMaker's managed training to pickup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Training\n",
    "Now we know that most of our features have skewed distributions, some are highly correlated with one another, and some appear to have non-linear relationships with our target variable.  Also, for targeting future prospects, good predictive accuracy is preferred to being able to explain why that prospect was targeted.  Taken together, these aspects make gradient boosted trees a good candidate algorithm.\n",
    "\n",
    "There are several intricacies to understanding the algorithm, but at a high level, gradient boosted trees works by combining predictions from many simple models, each of which tries to address the weaknesses of the previous models.  By doing this the collection of simple models can actually outperform large, complex models.  Other Amazon SageMaker notebooks elaborate on gradient boosting trees further and how they differ from similar algorithms.\n",
    "\n",
    "`xgboost` is an extremely popular, open-source package for gradient boosted trees.  It is computationally powerful, fully featured, and has been successfully used in many machine learning competitions.  Let's start with a simple `xgboost` model, trained using Amazon SageMaker's managed, distributed training framework.\n",
    "\n",
    "First we'll need to specify the ECR container location for Amazon SageMaker's implementation of XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost', repo_version='0.90-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, because we're training with the CSV file format, we'll create `s3_input`s that our training function can use as a pointer to the files in S3, which also specify that the content type is CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll need to specify training parameters to the estimator.  This includes:\n",
    "1. The `xgboost` algorithm container\n",
    "1. The IAM role to use\n",
    "1. Training instance type and count\n",
    "1. S3 location for output data\n",
    "1. Algorithm hyperparameters\n",
    "\n",
    "And then a `.fit()` function which specifies:\n",
    "1. S3 location for output data.  In this case we have both a training and validation set which are passed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-12 01:50:42 Starting - Starting the training job...\n",
      "2019-11-12 01:50:45 Starting - Launching requested ML instances......\n",
      "2019-11-12 01:51:43 Starting - Preparing the instances for training...\n",
      "2019-11-12 01:52:37 Downloading - Downloading input data...\n",
      "2019-11-12 01:52:53 Training - Downloading the training image..\u001b[31mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[31mINFO:sagemaker-containers:Failed to parse hyperparameter eval_metric value logloss to Json.\u001b[0m\n",
      "\u001b[31mReturning the value itself\u001b[0m\n",
      "\u001b[31mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[31mReturning the value itself\u001b[0m\n",
      "\u001b[31mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[31mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31mERROR:sagemaker-containers:Reporting training FAILURE\u001b[0m\n",
      "\u001b[31mERROR:sagemaker-containers:framework error: \u001b[0m\n",
      "\u001b[31mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/data_utils.py\", line 139, in _get_csv_delimiter\n",
      "    delimiter = csv.Sniffer().sniff(sample_csv_line).delimiter\n",
      "  File \"/miniconda3/lib/python3.7/csv.py\", line 188, in sniff\n",
      "    raise Error(\"Could not determine delimiter\")\u001b[0m\n",
      "\u001b[31m_csv.Error: Could not determine delimiter\n",
      "\u001b[0m\n",
      "\u001b[31mDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0m\n",
      "\u001b[31mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_containers/_trainer.py\", line 81, in train\n",
      "    entrypoint()\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/training.py\", line 94, in main\n",
      "    train(framework.training_env())\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/training.py\", line 90, in train\n",
      "    run_algorithm_mode()\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/training.py\", line 68, in run_algorithm_mode\n",
      "    checkpoint_config=checkpoint_config\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/algorithm_mode/train.py\", line 104, in sagemaker_train\n",
      "    train_dmatrix, val_dmatrix = get_validated_dmatrices(train_path, val_path, file_type, csv_weights, is_pipe)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/algorithm_mode/train.py\", line 55, in get_validated_dmatrices\n",
      "    validate_data_file_path(train_path, content_type)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/data_utils.py\", line 267, in validate_data_file_path\n",
      "    _validate_csv_format(data_file_path)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/data_utils.py\", line 211, in _validate_csv_format\n",
      "    _get_csv_delimiter(line_to_validate)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/data_utils.py\", line 142, in _get_csv_delimiter\n",
      "    raise exc.UserError(\"Could not determine delimiter on line {}:\\n{}\".format(sample_csv_line[:50], e))\u001b[0m\n",
      "\u001b[31msagemaker_algorithm_toolkit.exceptions.UserError: Could not determine delimiter on line \u001b[0m\n",
      "\u001b[31m:\u001b[0m\n",
      "\u001b[31mCould not determine delimiter\n",
      "\u001b[0m\n",
      "\u001b[31mCould not determine delimiter on line \u001b[0m\n",
      "\u001b[31m:\u001b[0m\n",
      "\u001b[31mCould not determine delimiter\u001b[0m\n",
      "\n",
      "2019-11-12 01:53:30 Uploading - Uploading generated training model\n",
      "2019-11-12 01:53:30 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job sagemaker-xgboost-2019-11-12-01-50-42-383: Failed. Reason: AlgorithmError: framework error: \nTraceback (most recent call last):\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/data_utils.py\", line 139, in _get_csv_delimiter\n    delimiter = csv.Sniffer().sniff(sample_csv_line).delimiter\n  File \"/miniconda3/lib/python3.7/csv.py\", line 188, in sniff\n    raise Error(\"Could not determine delimiter\")\n_csv.Error: Could not determine delimiter\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_containers/_trainer.py\", line 81, in train\n    entrypoint()\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/training.py\", line 94, in main\n    train(framework.training_env())\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/training.py\", line 90, in train\n    run_algorithm_mode()\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/training.py\", line 68, in run_algorithm_",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-fe82e0df0010>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms3_input_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms3_input_validation\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    902\u001b[0m         \"\"\"\n\u001b[1;32m    903\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   1513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1516\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 ),\n\u001b[1;32m   1155\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m             )\n\u001b[1;32m   1158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job sagemaker-xgboost-2019-11-12-01-50-42-383: Failed. Reason: AlgorithmError: framework error: \nTraceback (most recent call last):\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/data_utils.py\", line 139, in _get_csv_delimiter\n    delimiter = csv.Sniffer().sniff(sample_csv_line).delimiter\n  File \"/miniconda3/lib/python3.7/csv.py\", line 188, in sniff\n    raise Error(\"Could not determine delimiter\")\n_csv.Error: Could not determine delimiter\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_containers/_trainer.py\", line 81, in train\n    entrypoint()\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/training.py\", line 94, in main\n    train(framework.training_env())\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/training.py\", line 90, in train\n    run_algorithm_mode()\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/training.py\", line 68, in run_algorithm_"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=100,\n",
    "                        eval_metric='logloss')\n",
    "\n",
    "\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -y -c conda-forge xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "          \n",
    "import tarfile\n",
    "import pickle as pkl\n",
    "import xgboost\n",
    "\n",
    "# download the model artifact from AWS S3\n",
    "!aws s3 cp s3://sagemaker-sf-strategenics/sagemaker/DEMO-xgboost-noShow/output/sagemaker-xgboost-2019-11-08-00-23-47-910/output/model.tar.gz .\n",
    "\n",
    "#opens the downloaded model artifcat and loads it as 'model' variable\n",
    "tar = tarfile.open('model.tar.gz')\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "model = pkl.load(open('xgboost-model', 'rb'))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_names = dict(zip(model.feature_names, train_data[cols_input].columns))\n",
    "#model.feature_names = list(map_names.values())\n",
    "\n",
    "#plot feature importance\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "xgboost.plot_importance(model, importance_type='gain', max_num_features=30, height=0.8, ax=ax, show_values = False)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hosting\n",
    "Now that we've trained the `xgboost` algorithm on our data, let's deploy a model that's hosted behind a real-time endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=1,\n",
    "                           instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evaluation\n",
    "There are many ways to compare the performance of a machine learning model, but let's start by simply comparing actual to predicted values.  In this case, we're simply predicting whether the customer subscribed to a term deposit (`1`) or not (`0`), which produces a simple confusion matrix.\n",
    "\n",
    "First we'll need to determine how we pass data into and receive data from our endpoint.  Our data is currently stored as NumPy arrays in memory of our notebook instance.  To send it in an HTTP POST request, we'll serialize it as a CSV string and then decode the resulting CSV.\n",
    "\n",
    "*Note: For inference with CSV format, SageMaker XGBoost requires that the data does NOT include the target variable.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use a simple function to:\n",
    "1. Loop over our test dataset\n",
    "1. Split it into mini-batches of rows \n",
    "1. Convert those mini-batches to CSV string payloads (notice, we drop the target variable from our dataset first)\n",
    "1. Retrieve mini-batch predictions by invoking the XGBoost endpoint\n",
    "1. Collect predictions and convert from the CSV output our model provides into a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "test_data.describe()\n",
    "predictions = predict(test_data.drop(['No-show_No', 'No-show_Yes'], axis=1).as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll check our confusion matrix to see how well we predicted versus actuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=test_data['No-show_Yes'], columns=np.round(predictions), rownames=['actuals'], colnames=['predictions'],margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In summary, of the 11053 patients, we predicted 97 would be a no-show and 2,277 of them actually didn't turn up to the appointment.  We also had 2,180 that were no-shows but we predicted as turning up.  This is less than desirable.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Clean-up\n",
    "\n",
    "If you are done with this notebook, please run the cell below.  This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
